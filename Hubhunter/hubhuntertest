import requests
from bs4 import BeautifulSoup
import re
import time


def consultardados(nome, linguagem, localidade):
    resultados = []

    if " " in nome:
        nome = nome.replace(" ","+")

    if " " in localidade:
        localidade = localidade.replace(" ","+")

    if " " in linguagem:
        linguagens = linguagem.split(" ")
        linguagem = "+".join([f"language%3A{lang}" for lang in linguagens])

    link = f"https://github.com/search?q=location%3A{localidade}+language%3A{linguagem}+fullname%3A{nome}&type=users&p=1"

    print("Link da busca:", link)  # Adicionando instrução de depuração

    res = requests.get(link)

    if res.status_code == 200:
        dados = BeautifulSoup(res.text, 'html.parser')
        dados = dados.get_text()
        pagina = re.findall(r'"page_count":(\d+)', dados)
        pagina = int(pagina[0]) if pagina else 1  # Handle cases where page_count is not found

        print("Total de páginas:", pagina)  # Adicionando instrução de depuração

        for contpag in range(1, pagina + 1):
            link = f"https://github.com/search?q=location%3A{localidade}+language%3A{linguagem}+fullname%3A{nome}&type=users&p={contpag}"
            res = requests.get(link)
            if res.status_code == 200:
                dados = BeautifulSoup(res.text, 'html.parser')
                dados = dados.get_text()
                logins = re.findall(r'"display_login":"(.*?)"', dados)
                for cont in logins:
                    resultados.append(f"https://github.com/{cont}")
            else:
                print("Falha ao acessar o site:", res.status_code)  # Adicionando instrução de depuração
            time.sleep(1)
    else:
        print("Falha ao acessar o site:", res.status_code)  # Adicionando instrução de depuração


    return resultados
